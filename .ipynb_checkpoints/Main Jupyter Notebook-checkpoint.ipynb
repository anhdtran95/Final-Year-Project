{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is a notebook for the Final Year Project of Automated Classification of Bird Calls using Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import necessary python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Extract and save features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating for file: 0 of 320\n",
      "generating for file: 1 of 320\n",
      "generating for file: 2 of 320\n",
      "generating for file: 3 of 320\n",
      "generating for file: 4 of 320\n",
      "generating for file: 5 of 320\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../experiments/tool_functions/\")\n",
    "from tool_functions import saveFeaturesLabels\n",
    "from tool_functions import get_features_and_labels\n",
    "\n",
    "# saveFeaturesLabels(\"../experiments/XenoCantoBirdCalls\")\n",
    "features_train, labels_train, labelDict = get_features_and_labels(\"../experiments/XenoCantoBirdCalls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "filePath = \"../experiments/XenoCantoBirdCalls\"\n",
    "np.save(filePath + '/../featuresAndLabels/features_train.npy', features_train)\n",
    "np.save(filePath + '/../featuresAndLabels/labels_train.npy', labels_train)\n",
    " \n",
    "json.dump(labelDict, open(filePath + '/../featuresAndLabels/label_dict.json', 'w'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Load saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataPath = '../experiments/featuresAndLabels/'\n",
    "X = np.load(dataPath + 'features_train.npy')\n",
    "y = np.load(dataPath + 'labels_train.npy')\n",
    "labelDict = json.load(open(dataPath + 'label_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32452107,  0.45268199,  0.42375479, ...,  0.21762452,\n",
       "         0.20287356,  0.19329502],\n",
       "       [-0.15549828, -0.18446244, -0.20287187, ..., -0.11671576,\n",
       "        -0.06578301,  0.00834561],\n",
       "       [ 0.10912343,  0.11890982,  0.11091234, ...,  0.00610334,\n",
       "        -0.00599811, -0.00894454],\n",
       "       ...,\n",
       "       [-0.04203046, -0.03516751, -0.0013401 , ..., -0.02883249,\n",
       "         0.01656853,  0.03086294],\n",
       "       [ 0.11000172,  0.04372525, -0.09881219, ...,  0.0284042 ,\n",
       "         0.00292649, -0.01342744],\n",
       "       [-0.06125411, -0.06155291, -0.04435054, ..., -0.23144235,\n",
       "        -0.10338498,  0.07785888]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4) Split training and testing and perform one-hot labels encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "nb_epoch = 100\n",
    "batch_size = 50\n",
    "nb_classes = len(np.unique(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              90317824  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                7182      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 90,849,806\n",
      "Trainable params: 90,849,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3205 samples, validate on 1069 samples\n",
      "Epoch 1/100\n",
      "  50/3205 [..............................] - ETA: 13:21 - loss: 2.6499 - acc: 0.0800"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
